{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637d607f",
   "metadata": {},
   "source": [
    "***\n",
    "*Project:* Expressive Piano Generation\n",
    "\n",
    "*Author:* Jingwei Liu (Computer Music Ph.D., UC San Diego)\n",
    "***\n",
    "\n",
    "# <span style=\"background-color:darkorange; color:white; padding:2px 6px\">Application & ReadMe</span> \n",
    "\n",
    "\n",
    "# Expressive Piano Performance Generation (MIDI Format)\n",
    "\n",
    "## 1. Audio vs. MIDI\n",
    "\n",
    "- The music scene is shifted towards audio based composition and production, thus symbolic music generation is marginalized.\n",
    "\n",
    "- Symbolic music is frequently criticized for its stiffness and non-flexibility in generating listening-based music.\n",
    "\n",
    "- We argue that, **under the same expressivity of music replay, MIDI as a much more concise representation has advantage over the raw audio format in generation models**.\n",
    "\n",
    "### Multi-Arguments I/O\n",
    "\n",
    "Five arguments are extracted from the MIDI files as sufficient statistics for expressive piano performances. The five fields are:\n",
    "\n",
    "- Note value ($n$): a MIDI note number in range $[21,108]$.\n",
    "- Time shift ($t$): the onset difference between two subsequent notes in miliseconds, $t = 0$ gives perfectly simultaneous notes.\n",
    "- Duration ($d$): duration of the note in miliseconds.\n",
    "- Velocity ($v$): a number in range $[0,127]$, the MIDI default velocity representation.\n",
    "- Sustain pedal ($p$): the status of the sustain pedal, with binary value on/off (1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd9d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_midicsv as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2986d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") # operate on GPU \"cuda\" or CPU \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac394972",
   "metadata": {},
   "source": [
    "## 2. Listening-based Data Processing\n",
    "\n",
    "- *Abandonment of fixed grid.* Use time-shift events and duration measured in miliseconds to generate expressive timing.\n",
    "\n",
    "- *A homogeneous treatment of monophony and polyphony.* We claim that there is no real simultaneity of notes. For any two notes that are played by a human performer, there is always a time discrepancy between them, no matter how unnoticeable it is. It means that, since there are no simultaneous events, **we can always place the notes in sequential order, by their time onsets.**\n",
    "\n",
    "- *Not only the notes matter.* **The control events in MIDI may play a crucial role in musical expressivity** (eg. sustain pedal in piano generation). Please listen to \"Original.MID\" and \"no_sustain.mid\" for comparison.\n",
    "\n",
    "- *Mel quantization of auditory features.* Instead of equal division, like the Mel spectrogram, we divide the ranges into uneven chunks to better reflect the perceptual truth. We refer to **Weber’s law** for just noticeable differences as our theoretical foundation for the divisions, where the noticeable difference is proportional to the current value.\n",
    "\n",
    "<img src=\"Pictures/division_new.png\" style=\"width:800px\">\n",
    "<caption><center> Figure 1. The categorical distributions for given input features. The divisions obey Weber's law where the perceptual changes are proportional to the values. </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da615989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
       "           9,    10,    11,    12,    13,    14,    15,    16,    18,\n",
       "          20,    22,    24,    26,    28,    30,    32,    36,    40,\n",
       "          44,    48,    52,    56,    60,    64,    72,    80,    88,\n",
       "          96,   104,   112,   120,   128,   144,   160,   176,   192,\n",
       "         208,   224,   240,   256,   288,   320,   352,   384,   416,\n",
       "         448,   480,   512,   576,   640,   704,   768,   832,   896,\n",
       "         960,  1024,  1152,  1280,  1408,  1536,  1664,  1792,  1920,\n",
       "        2048,  2304,  2560,  2816,  3072,  3328,  3584,  3840,  4096,\n",
       "        4608,  5120,  5632,  6144,  6656,  7168,  7680,  8192,  9216,\n",
       "       10240, 11264, 12288, 13312, 14336, 15360, 16384, 18432, 20480,\n",
       "       22528, 24576, 26624, 28672, 30720, 32768, 35000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Shift Division\n",
    "division = np.array([2**i for i in range(16)])\n",
    "division = np.append(0,division)\n",
    "for j in range(3):\n",
    "    for i in range(division.size-1):\n",
    "        comb = division[i+1] + division[i]\n",
    "        if comb % 2 == 0:\n",
    "            division = np.append(division, int(comb/2))\n",
    "    division = np.unique(division)\n",
    "ts_division = division\n",
    "ts_division = np.append(ts_division, 35000)\n",
    "ts_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2da881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,    20,    30,    33,    35,    38,    40,    43,    45,\n",
       "          48,    50,    53,    55,    58,    60,    63,    65,    68,\n",
       "          70,    73,    75,    78,    80,    83,    85,    88,    90,\n",
       "          95,   100,   105,   110,   115,   120,   125,   130,   138,\n",
       "         145,   153,   160,   168,   175,   185,   195,   205,   215,\n",
       "         225,   235,   245,   255,   265,   275,   290,   305,   320,\n",
       "         335,   350,   365,   380,   395,   410,   425,   440,   455,\n",
       "         470,   485,   508,   530,   553,   575,   598,   620,   643,\n",
       "         665,   700,   735,   770,   805,   840,   875,   910,   945,\n",
       "         980,  1015,  1075,  1135,  1195,  1255,  1315,  1375,  1435,\n",
       "        1495,  1595,  1695,  1795,  1895,  1995,  2095,  2270,  2445,\n",
       "        2620,  2795,  3195,  3595,  3995,  4395,  4895,  5395,  5895,\n",
       "        6395,  6895,  7395,  7895,  8395,  8895,  9395,  9895, 10395,\n",
       "       15395, 20395, 30395, 40395])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duration Division\n",
    "division = np.append([0,20],np.arange(30,90,5))\n",
    "division = np.append(division, np.arange(90,130,10))\n",
    "division = np.append(division, np.arange(130,175,15))\n",
    "division = np.append(division, np.arange(175,275,20))\n",
    "division = np.append(division, np.arange(275,485,30))\n",
    "division = np.append(division, np.arange(485,665,45))\n",
    "division = np.append(division, np.arange(665,1015,70))\n",
    "division = np.append(division, np.arange(1015,1495,120))\n",
    "division = np.append(division, np.arange(1495,2095,200))\n",
    "division = np.append(division, np.arange(2095,2795,350))\n",
    "division = np.append(division, np.arange(2795,4395,800))\n",
    "division = np.append(division, np.arange(4395,10395,1000))\n",
    "division = np.append(division, np.arange(10395,31395,10000))\n",
    "for i in range(2,60):\n",
    "    division = np.append(division, int(np.ceil((division[i] + division[i+1])/2)))\n",
    "division.sort()\n",
    "dur_division = division\n",
    "dur_division = np.append(dur_division, 40395)\n",
    "dur_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f40a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-94, -74, -54, -34, -30, -26, -22, -20, -18, -16, -14, -12, -11,\n",
       "       -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,\n",
       "         3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  14,  16,  18,\n",
       "        20,  22,  26,  30,  34,  54,  74,  94, 110])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Velocity Change Division\n",
    "division_vel = np.append(np.arange(-22,-12,2),np.arange(-12,12))\n",
    "division_vel = np.append(division_vel, np.arange(12,22,2))\n",
    "division_vel = np.append(np.arange(-34,-22,4), division_vel)\n",
    "division_vel = np.append(division_vel, np.arange(22,34,4))\n",
    "division_vel = np.append(np.arange(-94,-34,20), division_vel)\n",
    "division_vel = np.append(division_vel, np.arange(34,105,20))\n",
    "vel_division = division_vel\n",
    "vel_division = np.append(vel_division, 110)\n",
    "vel_division"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af950c96",
   "metadata": {},
   "source": [
    "### Categorical Index of Multi-arguments\n",
    "\n",
    "- $x_n$ -- MIDI note number minus $21$. Original range $[21,108]$, note index range $[0,87]$.\n",
    "\n",
    "- $x_t$ -- Time shift in miliseconds categorized as Fig.1, index range $[0,104]$.\n",
    "\n",
    "- $x_d$ -- Duration in miliseconds categorized as Fig.1, index range $[0,119]$.\n",
    "\n",
    "- $x_v$ -- Velocity difference between two subsequent notes. Categorized as Fig.1, index range $[0,46]$\n",
    "\n",
    "- $x_p$ -- Sustain pedal status on/off, index range $[0,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68a319",
   "metadata": {},
   "source": [
    "## 3. Multi-arguments Sequential Model\n",
    "\n",
    "The temporal feature of the performance is captured by the sequential model, and the multi-arguments are inherently interdependent. To model their interdependencies, we decompose the temporal predictor into 5 separate LSTMs with inputs conditioned on previous outputs.\n",
    "\n",
    "<img src=\"Pictures/LSTM_5.jpg\" style=\"width:800px\">\n",
    "<caption><center> Figure 2. A way to Capture Interdependency among Arguments in a Multi-argument Sequential Model.</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509c0af",
   "metadata": {},
   "source": [
    "The LSTM cell functions as such:\n",
    "\n",
    "<img src=\"Pictures/LSTM cell.jpg\" style=\"width:800px\">\n",
    "<caption><center> Figure 3. LSTM cell. A recurrent neural network with forget and update gates that capture longer time dependencies. </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a446406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 1:\n",
    "        e_x = torch.exp(x - torch.max(x))\n",
    "        p_x = e_x / torch.sum(e_x)\n",
    "    else:\n",
    "        e_x = torch.exp(x - torch.max(x,axis=1,keepdims=True)[0])\n",
    "        p_x = e_x / torch.sum(e_x,axis=1,keepdims=True)\n",
    "    return p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a4743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_len, hidden_size, num_class, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.LSTM = nn.LSTM(input_len, hidden_size, num_layers, batch_first = True, device=dev)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_class, device=dev)\n",
    "        \n",
    "    def forward(self, X, hidden_state, cell_state): # input X (batch_size, seq_len, input_len)\n",
    "#         hidden_state = torch.zeros(self.num_layers, X.size(0), self.hidden_size, device = dev)\n",
    "#         cell_state = torch.zeros(self.num_layers, X.size(0), self.hidden_size, device = dev)\n",
    "        out, (hn, cn) = self.LSTM(X,(hidden_state, cell_state))\n",
    "        out = self.output_layer(out[:,-1,:]) # output (batch_size, seq_len, output_len)\n",
    "        return out, (hn, cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e57ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 150\n",
    "num_layers = 2\n",
    "\n",
    "input_len1 = 362 # 88+120+47+105+2\n",
    "num_class1 = 88 # predict note\n",
    "input_len2 = 362 + 88 \n",
    "num_class2 = 105 # predict time shift\n",
    "input_len3 = 362 + 193 \n",
    "num_class3 = 120 # predict duration\n",
    "input_len4 = 362 + 313 \n",
    "num_class4 = 47 # predict velocity change\n",
    "input_len5 = 362 + 360 \n",
    "num_class5 = 2 # predict pedal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3806efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LSTM(input_len1, hidden_size, num_class1, num_layers)\n",
    "model1.load_state_dict(torch.load(\"model1\", weights_only=True))\n",
    "\n",
    "model2 = LSTM(input_len2, hidden_size, num_class2, num_layers)\n",
    "model2.load_state_dict(torch.load(\"model2\", weights_only=True))\n",
    "\n",
    "model3 = LSTM(input_len3, hidden_size, num_class3, num_layers)\n",
    "model3.load_state_dict(torch.load(\"model3\", weights_only=True))\n",
    "\n",
    "model4 = LSTM(input_len4, hidden_size, num_class4, num_layers)\n",
    "model4.load_state_dict(torch.load(\"model4\", weights_only=True))\n",
    "\n",
    "model5 = LSTM(input_len5, hidden_size, num_class5, num_layers)\n",
    "model5.load_state_dict(torch.load(\"model5\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17b46d37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (LSTM): LSTM(362, 150, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=150, out_features=88, bias=True)\n",
      ")\n",
      "LSTM(\n",
      "  (LSTM): LSTM(450, 150, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=150, out_features=105, bias=True)\n",
      ")\n",
      "LSTM(\n",
      "  (LSTM): LSTM(555, 150, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=150, out_features=120, bias=True)\n",
      ")\n",
      "LSTM(\n",
      "  (LSTM): LSTM(675, 150, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=150, out_features=47, bias=True)\n",
      ")\n",
      "LSTM(\n",
      "  (LSTM): LSTM(722, 150, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=150, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1.eval())\n",
    "print(model2.eval())\n",
    "print(model3.eval())\n",
    "print(model4.eval())\n",
    "print(model5.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319af39",
   "metadata": {},
   "source": [
    "### Weight Attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a53848c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5358, 0.2361, 0.1864, 0.1415, 0.2741,    nan,    nan,    nan,    nan],\n",
       "        [0.2850, 0.2650, 0.2117, 0.1902, 0.2580, 0.3097,    nan,    nan,    nan],\n",
       "        [0.2666, 0.1725, 0.2603, 0.1966, 0.3085, 0.2960, 0.2260,    nan,    nan],\n",
       "        [0.2489, 0.1706, 0.1911, 0.2872, 0.1958, 0.2805, 0.2245, 0.2018,    nan],\n",
       "        [0.2229, 0.1790, 0.1991, 0.2080, 0.4362, 0.2240, 0.1959, 0.1940, 0.2179]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = [model1,model2,model3,model4,model5]\n",
    "param_att = torch.zeros(5,9)\n",
    "for i in range(param_att.shape[0]):\n",
    "    param_att[i,0] = model[i].state_dict()['LSTM.weight_ih_l0'][:,:88].abs().mean() #note\n",
    "    param_att[i,1] = model[i].state_dict()['LSTM.weight_ih_l0'][:,88:193].abs().mean() #time shift\n",
    "    param_att[i,2] = model[i].state_dict()['LSTM.weight_ih_l0'][:,193:313].abs().mean() #duration\n",
    "    param_att[i,3] = model[i].state_dict()['LSTM.weight_ih_l0'][:,313:360].abs().mean() #velocity change\n",
    "    param_att[i,4] = model[i].state_dict()['LSTM.weight_ih_l0'][:,360:362].abs().mean() #pedal\n",
    "    \n",
    "    param_att[i,5] = model[i].state_dict()['LSTM.weight_ih_l0'][:,362:450].abs().mean() #note_next\n",
    "    param_att[i,6] = model[i].state_dict()['LSTM.weight_ih_l0'][:,450:555].abs().mean() #time shift_next\n",
    "    param_att[i,7] = model[i].state_dict()['LSTM.weight_ih_l0'][:,555:675].abs().mean() #duration_next\n",
    "    param_att[i,8] = model[i].state_dict()['LSTM.weight_ih_l0'][:,675:722].abs().mean() #velocity change_next\n",
    "param_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3891b",
   "metadata": {},
   "source": [
    "The above matrix shows the attentions of each LSTM model on its input arguments, which can be visualized as below:\n",
    " \n",
    "<img src=\"Pictures/LSTM_5_weight.jpg\" style=\"width:800px\">\n",
    "<caption><center> Figure 4. Weight Attentions on Input Fields of 5 LSTM models.</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5105a",
   "metadata": {},
   "source": [
    "- *Observation 1*: Self-attention (attention on the argument of the predictive field) generally weighs more (the blue grid above the red predictive argument).\n",
    "- *Observation 2*: The 'note' field is informative in predicting all output arguments ($\\hat{x}_n$ field weights comparatively higher).\n",
    "- *Observation 3*: The arguments of the current note weigh more than that of the previous note (the second row has higher weights than the first row)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0983c0",
   "metadata": {},
   "source": [
    "## 4. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d7cd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_num1 = 100  # number of raw generations\n",
    "gen_num = gen_num1*6\n",
    "init_index = np.zeros((5,gen_num),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4901283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random initial notes\n",
    "init_index[0,:] = np.random.randint(88,size=(gen_num))\n",
    "init_index[1,:] = np.zeros(gen_num)\n",
    "init_index[2,:] = np.random.randint(100,size=(gen_num,))\n",
    "init_index[3,:] = np.random.randint(7,size=(gen_num,))+40\n",
    "init_index[4,:] = np.random.randint(2,size=(gen_num,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7faf3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specified initial notes\n",
    "init_index = np.array([[18,0,22,43,0],\n",
    "                      [41,0,31,44,0],\n",
    "                      [22,0,21,43,1],\n",
    "                      [52,0,73,43,0],\n",
    "                      [56,0,16,45,0],\n",
    "                      [35,0,29,46,0]])\n",
    "init_index = np.repeat(init_index,gen_num1,axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d321f17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18,  18,  18, ...,  35,  35,  35],\n",
       "       [ 88,  88,  88, ...,  88,  88,  88],\n",
       "       [215, 215, 215, ..., 222, 222, 222],\n",
       "       [356, 356, 356, ..., 359, 359, 359],\n",
       "       [360, 360, 360, ..., 360, 360, 360]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_len = 40 # number of notes to generate\n",
    "Generate_index = np.zeros((5,gen_num,gen_len+1),dtype = int)\n",
    "Generate_index[:,:,0] = init_index\n",
    "ind = init_index + np.array([0,88,193,313,360]).reshape(5,1)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6eea11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.zeros(gen_num,1,362*2,device=dev) # input (batch_size, 1, input_len)\n",
    "for i in range(gen_num):\n",
    "    input_tensor[i,0,ind[:,i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "91b66051",
   "metadata": {},
   "outputs": [],
   "source": [
    "hn1 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "cn1 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "hn2 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "cn2 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "hn3 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "cn3 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "hn4 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "cn4 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "hn5 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)\n",
    "cn5 = torch.zeros(num_layers, gen_num, hidden_size,device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1896489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    \"\"\"\n",
    "    Arguments: p -- row distribution. Torch tensor of shape (n_row, n_p) or (n_p,)\n",
    "    Returns: H -- row entropy. Torch tensor of shape (n_row,1) or a number\n",
    "    \"\"\"\n",
    "    if p.ndim == 1:\n",
    "        H = (-p * torch.where(p != 0, torch.log(p), -100)).sum()\n",
    "    else:\n",
    "        H = (-p * torch.where(p != 0, torch.log(p), -100)).sum(axis=1,keepdims=True)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "58d524c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "H1 = torch.zeros(gen_num, gen_len,device=dev)\n",
    "H2 = torch.zeros(gen_num, gen_len,device=dev)\n",
    "H3 = torch.zeros(gen_num, gen_len,device=dev)\n",
    "H4 = torch.zeros(gen_num, gen_len,device=dev)\n",
    "H5 = torch.zeros(gen_num, gen_len,device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7947f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,gen_len+1):\n",
    "    out1, (hn1, cn1) = model1(input_tensor[:,:,:362], hn1, cn1) # input (batch_size, 1, input_len)\n",
    "    p1 = softmax(out1.detach())\n",
    "    H1[:,i-1:i] = entropy(p1)\n",
    "    for j in range(gen_num):\n",
    "        note_next = np.random.choice(88, p=p1[j,:].cpu().numpy())\n",
    "        input_tensor[j,:,362 + note_next] = 1\n",
    "        Generate_index[0,j,i] = note_next\n",
    "    \n",
    "    out2, (hn2, cn2) = model2(input_tensor[:,:,:450], hn2, cn2)\n",
    "    p2 = softmax(out2.detach())\n",
    "    H2[:,i-1:i] = entropy(p2)\n",
    "    for j in range(gen_num):\n",
    "        time_shift_next = np.random.choice(105, p=p2[j,:].cpu().numpy())\n",
    "        input_tensor[j,:,450 + time_shift_next] = 1\n",
    "        Generate_index[1,j,i] = time_shift_next\n",
    "    \n",
    "    out3, (hn3, cn3) = model3(input_tensor[:,:,:555], hn3, cn3)\n",
    "    p3 = softmax(out3.detach())\n",
    "    H3[:,i-1:i] = entropy(p3)\n",
    "    for j in range(gen_num):\n",
    "        duration_next = np.random.choice(120, p=p3[j,:].cpu().numpy())\n",
    "        input_tensor[j,:,555 + duration_next] = 1\n",
    "        Generate_index[2,j,i] = duration_next\n",
    "    \n",
    "    out4, (hn4, cn4) = model4(input_tensor[:,:,:675], hn4, cn4)\n",
    "    p4 = softmax(out4.detach())\n",
    "    H4[:,i-1:i] = entropy(p4)\n",
    "    for j in range(gen_num):\n",
    "        velocity_next = np.random.choice(47, p=p4[j,:].cpu().numpy())\n",
    "        input_tensor[j,:,675 + velocity_next] = 1\n",
    "        Generate_index[3,j,i] = velocity_next\n",
    "    \n",
    "    out5, (hn5, cn5) = model5(input_tensor[:,:,:722], hn5, cn5)\n",
    "    p5 = softmax(out5.detach())\n",
    "    H5[:,i-1:i] = entropy(p5)\n",
    "    for j in range(gen_num):\n",
    "        pedal_next = np.random.choice(2, p=p5[j,:].cpu().numpy())\n",
    "        input_tensor[j,:,722 + pedal_next] = 1\n",
    "        Generate_index[4,j,i] = pedal_next\n",
    "    \n",
    "    next_tensor = torch.zeros(gen_num,1,362*2,device=dev)\n",
    "    next_tensor[:,:,:362] = input_tensor[:,:,362:]\n",
    "    input_tensor = next_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "63257517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 43, 330, 182, 418, 542, 272, 402, 480], device='cuda:0')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select generations by least entropy to avoid exposure bias\n",
    "values, indices = (H1 + H2 + H3 + H4 + H5).mean(axis=1).sort()\n",
    "sel_num = 8  # number of selected samples\n",
    "sel_ind = indices[0:sel_num]\n",
    "sel_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab90e1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 328)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generate_index_sel = Generate_index[:,sel_ind[0],:]\n",
    "for i in range(1,sel_num):\n",
    "    Generate_index[1,sel_ind[i],0] = 75   # 3s time shift\n",
    "    Generate_index_sel = np.concatenate((Generate_index_sel, Generate_index[:,sel_ind[i],:]),axis=1)\n",
    "Generate_index_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b273613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transit Index to Real Value\n",
    "Generation = np.zeros((5,(gen_len+1)*sel_num),dtype = int)\n",
    "Generation[0,:] = Generate_index_sel[0,:] + 21 # note value\n",
    "Generation[4,:] = Generate_index_sel[4,:] # pedal\n",
    "vel = 0\n",
    "for i in range((gen_len+1)*sel_num):\n",
    "    Generation[1,i] = np.random.choice(np.arange(ts_division[Generate_index_sel[1,i]],ts_division[Generate_index_sel[1,i]+1]))\n",
    "    Generation[2,i] = np.random.choice(np.arange(dur_division[Generate_index_sel[2,i]],dur_division[Generate_index_sel[2,i]+1]))\n",
    "    vel_change = np.random.choice(np.arange(vel_division[Generate_index_sel[3,i]],vel_division[Generate_index_sel[3,i]+1]))\n",
    "    Generation[3,i] = np.clip(vel + vel_change,20,120)\n",
    "    vel = Generation[3,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f445c",
   "metadata": {},
   "source": [
    "### Write to MIDI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6fc84e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Type</th>\n",
       "      <th>Note</th>\n",
       "      <th>Velocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Note_on_c</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>Control_c</td>\n",
       "      <td>64</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>Note_off_c</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>Note_on_c</td>\n",
       "      <td>89</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203</td>\n",
       "      <td>Note_on_c</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>40465</td>\n",
       "      <td>Note_off_c</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>40480</td>\n",
       "      <td>Note_on_c</td>\n",
       "      <td>81</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>40505</td>\n",
       "      <td>Note_on_c</td>\n",
       "      <td>50</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>40553</td>\n",
       "      <td>Note_off_c</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>40557</td>\n",
       "      <td>Note_off_c</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        Type Note Velocity\n",
       "0        0   Note_on_c   39       42\n",
       "1       24   Control_c   64      127\n",
       "2       81  Note_off_c   39        0\n",
       "3      116   Note_on_c   89       33\n",
       "4      203   Note_on_c   51       20\n",
       "..     ...         ...  ...      ...\n",
       "678  40465  Note_off_c   78        0\n",
       "679  40480   Note_on_c   81      104\n",
       "680  40505   Note_on_c   50       95\n",
       "681  40553  Note_off_c   50        0\n",
       "682  40557  Note_off_c   81        0\n",
       "\n",
       "[683 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = np.cumsum(Generation[1,:])\n",
    "MIDI_format = pd.DataFrame(columns=['Time','Type','Note','Velocity'])\n",
    "pedal = 0\n",
    "for i in range(Generation.shape[1]):\n",
    "    MIDI_format = pd.concat([MIDI_format, pd.DataFrame([{'Time': time[i],\n",
    "                         'Type': 'Note_on_c',\n",
    "                         'Note': Generation[0,i],\n",
    "                         'Velocity': Generation[3,i]}])], ignore_index=True)\n",
    "    MIDI_format = pd.concat([MIDI_format, pd.DataFrame([{'Time': (time[i] + Generation[2,i]),\n",
    "                         'Type': 'Note_off_c',\n",
    "                         'Note': Generation[0,i],\n",
    "                         'Velocity': 0}])], ignore_index=True)\n",
    "    if Generation[4,i] != pedal:\n",
    "        pedal = Generation[4,i]\n",
    "        if i == 0:\n",
    "            MIDI_format = pd.concat([MIDI_format, pd.DataFrame([{'Time': 0,\n",
    "                                 'Type': 'Control_c',\n",
    "                                 'Note': 64,\n",
    "                                 'Velocity': pedal*127}])], ignore_index=True)\n",
    "        else:\n",
    "            MIDI_format = pd.concat([MIDI_format, pd.DataFrame([{'Time': np.random.choice(np.arange(time[i-1],time[i]+1)),\n",
    "                                 'Type': 'Control_c',\n",
    "                                 'Note': 64,\n",
    "                                 'Velocity': pedal*127}])], ignore_index=True)\n",
    "MIDI_format = MIDI_format.sort_values('Time')\n",
    "MIDI_format = MIDI_format.reset_index(drop=True)\n",
    "MIDI_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "43278006",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_csv = open(\"midi.csv\", 'w')\n",
    "generated_csv.write(\"0,0,Header,0,1,480\\n\")\n",
    "generated_csv.write(\"1,0,Start_track\\n\")\n",
    "generated_csv.write(\"1,0,Tempo,480000\\n\")\n",
    "generated_csv.write(\"1,0,Program_c, 0, 0\\n\")\n",
    "\n",
    "for i in range(len(MIDI_format)):\n",
    "    generated_csv.write(\"1,\"+str(MIDI_format['Time'][i])+\",\"+ MIDI_format['Type'][i] +\",0,\"+str(MIDI_format['Note'][i])+\",\"+str(MIDI_format['Velocity'][i])+\"\\n\")\n",
    "    \n",
    "end_time = MIDI_format['Time'][i] + 480\n",
    "generated_csv.write(\"1,\" + str(end_time) +\", End_track\\n\")\n",
    "generated_csv.write(\"0, 0, End_of_file\")\n",
    "generated_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d1b84ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the CSV output of the previous command back into a MIDI file\n",
    "midi_object = pm.csv_to_midi(\"midi.csv\")\n",
    "\n",
    "# Save the parsed MIDI file to disk\n",
    "with open(\"C://Users/79244/Desktop/generated_lstm.mid\", \"wb\") as output_file:\n",
    "# with open(\"generated_note_55_61_42_0_0_zero.mid\", \"wb\") as output_file:\n",
    "    midi_writer = pm.FileWriter(output_file)\n",
    "    midi_writer.write(midi_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfac453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
